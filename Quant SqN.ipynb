{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantised SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to:\n",
    "!export PYTHONPATH=$(readlink -m ./pytorch-playground):$PYTHONPATH\n",
    "from utee import misc, quant, selector\n",
    "from imagenet import squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting GPU: ['0']\n",
      "Building and initializing squeezenet_v1 parameters\n"
     ]
    }
   ],
   "source": [
    "gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=1, selected_gpus=None)\n",
    "input_size = 224\n",
    "\n",
    "assert torch.cuda.is_available(), 'no cuda'\n",
    "torch.manual_seed(117)\n",
    "torch.cuda.manual_seed(117)\n",
    "\n",
    "model_raw, ds_fetcher, is_imagenet = selector.select('squeezenet_v1', model_root='~/.torch/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting model\n",
    "There is the existing ONNX exporter. Either modify that, or manually add functions to each type of Module and call them recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying for quantised training\n",
    "Easiest would be to modify SqN source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying for quantised inference\n",
    "Easiest is probably also modifying source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "Search GitHub; there seem to be plenty of implementations. E.g. https://github.com/marvis/pytorch-mobilenet\n",
    "There are also implementations for v2.\n",
    "\n",
    "## MobileNet-SSD\n",
    "Try modifying https://github.com/amdegroot/ssd.pytorch:\n",
    "  - Use MobileNet feature extractor\n",
    "  - Use dw convolutions in SSD (SSDLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.group1.squeeze.weight', 'features.3.group1.squeeze.bias', 'features.3.group2.expand1x1.weight', 'features.3.group2.expand1x1.bias', 'features.3.group3.expand3x3.weight', 'features.3.group3.expand3x3.bias', 'features.4.group1.squeeze.weight', 'features.4.group1.squeeze.bias', 'features.4.group2.expand1x1.weight', 'features.4.group2.expand1x1.bias', 'features.4.group3.expand3x3.weight', 'features.4.group3.expand3x3.bias', 'features.6.group1.squeeze.weight', 'features.6.group1.squeeze.bias', 'features.6.group2.expand1x1.weight', 'features.6.group2.expand1x1.bias', 'features.6.group3.expand3x3.weight', 'features.6.group3.expand3x3.bias', 'features.7.group1.squeeze.weight', 'features.7.group1.squeeze.bias', 'features.7.group2.expand1x1.weight', 'features.7.group2.expand1x1.bias', 'features.7.group3.expand3x3.weight', 'features.7.group3.expand3x3.bias', 'features.9.group1.squeeze.weight', 'features.9.group1.squeeze.bias', 'features.9.group2.expand1x1.weight', 'features.9.group2.expand1x1.bias', 'features.9.group3.expand3x3.weight', 'features.9.group3.expand3x3.bias', 'features.10.group1.squeeze.weight', 'features.10.group1.squeeze.bias', 'features.10.group2.expand1x1.weight', 'features.10.group2.expand1x1.bias', 'features.10.group3.expand3x3.weight', 'features.10.group3.expand3x3.bias', 'features.11.group1.squeeze.weight', 'features.11.group1.squeeze.bias', 'features.11.group2.expand1x1.weight', 'features.11.group2.expand1x1.bias', 'features.11.group3.expand3x3.weight', 'features.11.group3.expand3x3.bias', 'features.12.group1.squeeze.weight', 'features.12.group1.squeeze.bias', 'features.12.group2.expand1x1.weight', 'features.12.group2.expand1x1.bias', 'features.12.group3.expand3x3.weight', 'features.12.group3.expand3x3.bias', 'classifier.1.weight', 'classifier.1.bias'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
