{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantised SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.jit as jit\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to:\n",
    "!export PYTHONPATH=$(readlink -m ./pytorch-playground):$PYTHONPATH\n",
    "from utee import misc, quant, selector\n",
    "from imagenet import squeezenet\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting GPU: ['0']\n",
      "Building and initializing squeezenet_v1 parameters\n"
     ]
    }
   ],
   "source": [
    "gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=1, selected_gpus='0')\n",
    "ngpu = len(gpu)\n",
    "input_size = 224\n",
    "\n",
    "batch_size = 100\n",
    "data_root='/tmp/public_dataset/pytorch/'\n",
    "\n",
    "assert torch.cuda.is_available(), 'no cuda'\n",
    "torch.manual_seed(117)\n",
    "torch.cuda.manual_seed(117)\n",
    "\n",
    "# load model and dataset fetcher\n",
    "model_raw, ds_fetcher, is_imagenet = selector.select('squeezenet_v1', model_root='~/.torch/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pickle object from /tmp/public_dataset/pytorch/imagenet-data/val224.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building IMAGENET data loader, 50000 for train, 50000 for test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> Done (6.2928 s)\n",
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/500 [00:00<01:35,  5.22it/s]\u001b[A\n",
      "  0%|          | 2/500 [00:00<01:31,  5.47it/s]\u001b[A\n",
      "  1%|          | 3/500 [00:00<01:27,  5.66it/s]\u001b[A\n",
      "  1%|          | 4/500 [00:00<01:24,  5.86it/s]\u001b[A\n",
      "  1%|          | 5/500 [00:00<01:22,  6.01it/s]\u001b[A\n",
      "  1%|          | 6/500 [00:00<01:20,  6.11it/s]\u001b[A\n",
      "  1%|▏         | 7/500 [00:01<01:19,  6.19it/s]\u001b[A\n",
      "  2%|▏         | 8/500 [00:01<01:18,  6.25it/s]\u001b[A\n",
      "  2%|▏         | 9/500 [00:01<01:17,  6.30it/s]\u001b[A\n",
      "  2%|▏         | 10/500 [00:01<01:17,  6.34it/s]\u001b[A\n",
      "  2%|▏         | 11/500 [00:01<01:16,  6.36it/s]\u001b[A\n",
      "  2%|▏         | 12/500 [00:01<01:16,  6.38it/s]\u001b[A\n",
      "  3%|▎         | 13/500 [00:02<01:16,  6.40it/s]\u001b[A\n",
      "  3%|▎         | 14/500 [00:02<01:15,  6.42it/s]\u001b[A\n",
      "  3%|▎         | 15/500 [00:02<01:15,  6.44it/s]\u001b[A\n",
      "  3%|▎         | 16/500 [00:02<01:14,  6.45it/s]\u001b[A\n",
      "  3%|▎         | 17/500 [00:02<01:14,  6.47it/s]\u001b[A\n",
      "  4%|▎         | 18/500 [00:02<01:14,  6.48it/s]\u001b[A\n",
      "  4%|▍         | 19/500 [00:02<01:14,  6.49it/s]\u001b[A\n",
      "  4%|▍         | 20/500 [00:03<01:13,  6.50it/s]\u001b[A\n",
      "  4%|▍         | 21/500 [00:03<01:13,  6.51it/s]\u001b[A\n",
      "  4%|▍         | 22/500 [00:03<01:13,  6.51it/s]\u001b[A\n",
      "  5%|▍         | 23/500 [00:03<01:13,  6.51it/s]\u001b[A\n",
      "  5%|▍         | 24/500 [00:03<01:13,  6.52it/s]\u001b[A\n",
      "  5%|▌         | 25/500 [00:03<01:12,  6.52it/s]\u001b[A\n",
      "  5%|▌         | 26/500 [00:03<01:12,  6.53it/s]\u001b[A\n",
      "  5%|▌         | 27/500 [00:04<01:12,  6.53it/s]\u001b[A\n",
      "  6%|▌         | 28/500 [00:04<01:12,  6.54it/s]\u001b[A\n",
      "  6%|▌         | 29/500 [00:04<01:11,  6.54it/s]\u001b[A\n",
      "  6%|▌         | 30/500 [00:04<01:11,  6.55it/s]\u001b[A\n",
      "  6%|▌         | 31/500 [00:04<01:11,  6.55it/s]\u001b[A\n",
      "  6%|▋         | 32/500 [00:04<01:11,  6.55it/s]\u001b[A\n",
      "  7%|▋         | 33/500 [00:05<01:11,  6.55it/s]\u001b[A\n",
      "  7%|▋         | 34/500 [00:05<01:11,  6.55it/s]\u001b[A\n",
      "  7%|▋         | 35/500 [00:05<01:10,  6.56it/s]\u001b[A\n",
      "  7%|▋         | 36/500 [00:05<01:10,  6.56it/s]\u001b[A\n",
      "  7%|▋         | 37/500 [00:05<01:10,  6.56it/s]\u001b[A\n",
      "  8%|▊         | 38/500 [00:05<01:10,  6.57it/s]\u001b[A\n",
      "  8%|▊         | 39/500 [00:05<01:10,  6.57it/s]\u001b[A\n",
      "  8%|▊         | 40/500 [00:06<01:09,  6.57it/s]\u001b[A\n",
      "  8%|▊         | 41/500 [00:06<01:09,  6.57it/s]\u001b[A\n",
      "  8%|▊         | 42/500 [00:06<01:09,  6.57it/s]\u001b[A\n",
      "  9%|▊         | 43/500 [00:06<01:09,  6.57it/s]\u001b[A\n",
      "  9%|▉         | 44/500 [00:06<01:09,  6.57it/s]\u001b[A\n",
      "  9%|▉         | 45/500 [00:06<01:09,  6.58it/s]\u001b[A\n",
      "  9%|▉         | 46/500 [00:06<01:08,  6.58it/s]\u001b[A\n",
      "  9%|▉         | 47/500 [00:07<01:08,  6.58it/s]\u001b[A\n",
      " 10%|▉         | 48/500 [00:07<01:08,  6.59it/s]\u001b[A\n",
      " 10%|▉         | 49/500 [00:07<01:08,  6.59it/s]\u001b[A\n",
      " 10%|█         | 50/500 [00:07<01:08,  6.59it/s]\u001b[A\n",
      " 10%|█         | 51/500 [00:07<01:08,  6.59it/s]\u001b[A\n",
      " 10%|█         | 52/500 [00:07<01:08,  6.59it/s]\u001b[A\n",
      " 11%|█         | 53/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 11%|█         | 54/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 11%|█         | 55/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 11%|█         | 56/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 11%|█▏        | 57/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 12%|█▏        | 58/500 [00:08<01:07,  6.59it/s]\u001b[A\n",
      " 12%|█▏        | 59/500 [00:08<01:06,  6.59it/s]\u001b[A\n",
      " 12%|█▏        | 60/500 [00:09<01:06,  6.59it/s]\u001b[A\n",
      " 12%|█▏        | 61/500 [00:09<01:06,  6.60it/s]\u001b[A\n",
      " 12%|█▏        | 62/500 [00:09<01:06,  6.60it/s]\u001b[A\n",
      " 13%|█▎        | 63/500 [00:09<01:06,  6.60it/s]\u001b[A\n",
      " 13%|█▎        | 64/500 [00:09<01:06,  6.60it/s]\u001b[A\n",
      " 13%|█▎        | 65/500 [00:09<01:05,  6.60it/s]\u001b[A\n",
      " 13%|█▎        | 66/500 [00:10<01:05,  6.60it/s]\u001b[A\n",
      " 13%|█▎        | 67/500 [00:10<01:05,  6.60it/s]\u001b[A\n",
      " 14%|█▎        | 68/500 [00:10<01:05,  6.60it/s]\u001b[A\n",
      " 14%|█▍        | 69/500 [00:10<01:05,  6.60it/s]\u001b[A\n",
      " 14%|█▍        | 70/500 [00:10<01:05,  6.60it/s]\u001b[A\n",
      " 14%|█▍        | 71/500 [00:10<01:04,  6.60it/s]\u001b[A\n",
      " 14%|█▍        | 72/500 [00:10<01:04,  6.60it/s]\u001b[A\n",
      " 15%|█▍        | 73/500 [00:11<01:04,  6.60it/s]\u001b[A\n",
      " 15%|█▍        | 74/500 [00:11<01:04,  6.60it/s]\u001b[A\n",
      " 15%|█▌        | 75/500 [00:11<01:04,  6.60it/s]\u001b[A\n",
      " 15%|█▌        | 76/500 [00:11<01:04,  6.60it/s]\u001b[A\n",
      " 15%|█▌        | 77/500 [00:11<01:04,  6.60it/s]\u001b[A\n",
      " 16%|█▌        | 78/500 [00:11<01:03,  6.60it/s]\u001b[A\n",
      " 16%|█▌        | 79/500 [00:11<01:03,  6.61it/s]\u001b[A\n",
      " 16%|█▌        | 80/500 [00:12<01:03,  6.61it/s]\u001b[A\n",
      " 16%|█▌        | 81/500 [00:12<01:03,  6.61it/s]\u001b[A\n",
      " 16%|█▋        | 82/500 [00:12<01:03,  6.61it/s]\u001b[A\n",
      " 17%|█▋        | 83/500 [00:12<01:03,  6.61it/s]\u001b[A\n",
      " 17%|█▋        | 84/500 [00:12<01:02,  6.61it/s]\u001b[A\n",
      " 17%|█▋        | 85/500 [00:12<01:02,  6.61it/s]\u001b[A\n",
      " 17%|█▋        | 86/500 [00:13<01:02,  6.61it/s]\u001b[A\n",
      " 17%|█▋        | 87/500 [00:13<01:02,  6.61it/s]\u001b[A\n",
      " 18%|█▊        | 88/500 [00:13<01:02,  6.61it/s]\u001b[A\n",
      " 18%|█▊        | 89/500 [00:13<01:02,  6.61it/s]\u001b[A\n",
      " 18%|█▊        | 90/500 [00:13<01:02,  6.61it/s]\u001b[A\n",
      " 18%|█▊        | 91/500 [00:13<01:01,  6.61it/s]\u001b[A\n",
      " 18%|█▊        | 92/500 [00:13<01:01,  6.61it/s]\u001b[A\n",
      " 19%|█▊        | 93/500 [00:14<01:01,  6.61it/s]\u001b[A\n",
      " 19%|█▉        | 94/500 [00:14<01:01,  6.61it/s]\u001b[A\n",
      " 19%|█▉        | 95/500 [00:14<01:01,  6.61it/s]\u001b[A\n",
      " 19%|█▉        | 96/500 [00:14<01:01,  6.61it/s]\u001b[A\n",
      " 19%|█▉        | 97/500 [00:14<01:00,  6.61it/s]\u001b[A\n",
      " 20%|█▉        | 98/500 [00:14<01:00,  6.61it/s]\u001b[A\n",
      " 20%|█▉        | 99/500 [00:14<01:00,  6.61it/s]\u001b[A\n",
      " 20%|██        | 100/500 [00:15<01:00,  6.61it/s]\u001b[A\n",
      " 20%|██        | 101/500 [00:15<01:00,  6.61it/s]\u001b[A\n",
      " 20%|██        | 102/500 [00:15<01:00,  6.61it/s]\u001b[A\n",
      " 21%|██        | 103/500 [00:15<01:00,  6.61it/s]\u001b[A\n",
      " 21%|██        | 104/500 [00:15<00:59,  6.61it/s]\u001b[A\n",
      " 21%|██        | 105/500 [00:15<00:59,  6.61it/s]\u001b[A\n",
      " 21%|██        | 106/500 [00:16<00:59,  6.61it/s]\u001b[A\n",
      " 21%|██▏       | 107/500 [00:16<00:59,  6.61it/s]\u001b[A\n",
      " 22%|██▏       | 108/500 [00:16<00:59,  6.61it/s]\u001b[A\n",
      " 22%|██▏       | 109/500 [00:16<00:59,  6.61it/s]\u001b[A\n",
      " 22%|██▏       | 110/500 [00:16<00:58,  6.61it/s]\u001b[A\n",
      " 22%|██▏       | 111/500 [00:16<00:58,  6.61it/s]\u001b[A\n",
      " 22%|██▏       | 112/500 [00:16<00:58,  6.61it/s]\u001b[A\n",
      " 23%|██▎       | 113/500 [00:17<00:58,  6.61it/s]\u001b[A\n",
      " 23%|██▎       | 114/500 [00:17<00:58,  6.61it/s]\u001b[A\n",
      " 23%|██▎       | 115/500 [00:17<00:58,  6.61it/s]\u001b[A\n",
      " 23%|██▎       | 116/500 [00:17<00:58,  6.62it/s]\u001b[A\n",
      " 23%|██▎       | 117/500 [00:17<00:57,  6.62it/s]\u001b[A\n",
      " 24%|██▎       | 118/500 [00:17<00:57,  6.62it/s]\u001b[A\n",
      " 24%|██▍       | 119/500 [00:17<00:57,  6.62it/s]\u001b[A\n",
      " 24%|██▍       | 120/500 [00:18<00:57,  6.62it/s]\u001b[A\n",
      " 24%|██▍       | 121/500 [00:18<00:57,  6.62it/s]\u001b[A\n",
      " 24%|██▍       | 122/500 [00:18<00:57,  6.62it/s]\u001b[A\n",
      " 25%|██▍       | 123/500 [00:18<00:56,  6.62it/s]\u001b[A\n",
      " 25%|██▍       | 124/500 [00:18<00:56,  6.62it/s]\u001b[A\n",
      " 25%|██▌       | 125/500 [00:18<00:56,  6.62it/s]\u001b[A\n",
      " 25%|██▌       | 126/500 [00:19<00:56,  6.62it/s]\u001b[A\n",
      " 25%|██▌       | 127/500 [00:19<00:56,  6.62it/s]\u001b[A\n",
      " 26%|██▌       | 128/500 [00:19<00:56,  6.62it/s]\u001b[A\n",
      " 26%|██▌       | 129/500 [00:19<00:56,  6.62it/s]\u001b[A\n",
      " 26%|██▌       | 130/500 [00:19<00:55,  6.62it/s]\u001b[A\n",
      " 26%|██▌       | 131/500 [00:19<00:55,  6.62it/s]\u001b[A\n",
      " 26%|██▋       | 132/500 [00:19<00:55,  6.62it/s]\u001b[A\n",
      " 27%|██▋       | 133/500 [00:20<00:55,  6.62it/s]\u001b[A\n",
      " 27%|██▋       | 134/500 [00:20<00:55,  6.62it/s]\u001b[A\n",
      " 27%|██▋       | 135/500 [00:20<00:55,  6.62it/s]\u001b[A\n",
      " 27%|██▋       | 136/500 [00:20<00:54,  6.62it/s]\u001b[A\n",
      " 27%|██▋       | 137/500 [00:20<00:54,  6.62it/s]\u001b[A\n",
      " 28%|██▊       | 138/500 [00:20<00:54,  6.62it/s]\u001b[A\n",
      " 28%|██▊       | 139/500 [00:21<00:54,  6.62it/s]\u001b[A\n",
      " 28%|██▊       | 140/500 [00:21<00:54,  6.62it/s]\u001b[A\n",
      " 28%|██▊       | 141/500 [00:21<00:54,  6.62it/s]\u001b[A\n",
      " 28%|██▊       | 142/500 [00:21<00:54,  6.62it/s]\u001b[A\n",
      " 29%|██▊       | 143/500 [00:21<00:53,  6.62it/s]\u001b[A\n",
      " 29%|██▉       | 144/500 [00:21<00:53,  6.62it/s]\u001b[A\n",
      " 29%|██▉       | 145/500 [00:21<00:53,  6.62it/s]\u001b[A\n",
      " 29%|██▉       | 146/500 [00:22<00:53,  6.62it/s]\u001b[A\n",
      " 29%|██▉       | 147/500 [00:22<00:53,  6.62it/s]\u001b[A\n",
      " 30%|██▉       | 148/500 [00:22<00:53,  6.62it/s]\u001b[A\n",
      " 30%|██▉       | 149/500 [00:22<00:53,  6.62it/s]\u001b[A\n",
      " 30%|███       | 150/500 [00:22<00:52,  6.62it/s]\u001b[A\n",
      " 30%|███       | 151/500 [00:22<00:52,  6.62it/s]\u001b[A\n",
      " 30%|███       | 152/500 [00:22<00:52,  6.62it/s]\u001b[A\n",
      " 31%|███       | 153/500 [00:23<00:52,  6.62it/s]\u001b[A\n",
      " 31%|███       | 154/500 [00:23<00:52,  6.62it/s]\u001b[A\n",
      " 31%|███       | 155/500 [00:23<00:52,  6.62it/s]\u001b[A\n",
      " 31%|███       | 156/500 [00:23<00:51,  6.62it/s]\u001b[A\n",
      " 31%|███▏      | 157/500 [00:23<00:51,  6.62it/s]\u001b[A\n",
      " 32%|███▏      | 158/500 [00:23<00:51,  6.62it/s]\u001b[A\n",
      " 32%|███▏      | 159/500 [00:24<00:51,  6.62it/s]\u001b[A\n",
      " 32%|███▏      | 160/500 [00:24<00:51,  6.62it/s]\u001b[A\n",
      " 32%|███▏      | 161/500 [00:24<00:51,  6.62it/s]\u001b[A\n",
      " 32%|███▏      | 162/500 [00:24<00:51,  6.62it/s]\u001b[A\n",
      " 33%|███▎      | 163/500 [00:24<00:50,  6.62it/s]\u001b[A\n",
      " 33%|███▎      | 164/500 [00:24<00:50,  6.62it/s]\u001b[A\n",
      " 33%|███▎      | 165/500 [00:24<00:50,  6.62it/s]\u001b[A\n",
      " 33%|███▎      | 166/500 [00:25<00:50,  6.62it/s]\u001b[A\n",
      " 33%|███▎      | 167/500 [00:25<00:50,  6.62it/s]\u001b[A\n",
      " 34%|███▎      | 168/500 [00:25<00:50,  6.62it/s]\u001b[A\n",
      " 34%|███▍      | 169/500 [00:25<00:49,  6.62it/s]\u001b[A\n",
      " 34%|███▍      | 170/500 [00:25<00:49,  6.62it/s]\u001b[A\n",
      " 34%|███▍      | 171/500 [00:25<00:49,  6.62it/s]\u001b[A\n",
      " 34%|███▍      | 172/500 [00:25<00:49,  6.62it/s]\u001b[A\n",
      " 35%|███▍      | 173/500 [00:26<00:49,  6.62it/s]\u001b[A\n",
      " 35%|███▍      | 174/500 [00:26<00:49,  6.62it/s]\u001b[A\n",
      " 35%|███▌      | 175/500 [00:26<00:49,  6.62it/s]\u001b[A\n",
      " 35%|███▌      | 176/500 [00:26<00:48,  6.62it/s]\u001b[A\n",
      " 35%|███▌      | 177/500 [00:26<00:48,  6.62it/s]\u001b[A\n",
      " 36%|███▌      | 178/500 [00:26<00:48,  6.62it/s]\u001b[A\n",
      " 36%|███▌      | 179/500 [00:27<00:48,  6.62it/s]\u001b[A\n",
      " 36%|███▌      | 180/500 [00:27<00:48,  6.62it/s]\u001b[A\n",
      " 36%|███▌      | 181/500 [00:27<00:48,  6.62it/s]\u001b[A\n",
      " 36%|███▋      | 182/500 [00:27<00:48,  6.62it/s]\u001b[A\n",
      " 37%|███▋      | 183/500 [00:27<00:47,  6.62it/s]\u001b[A\n",
      " 37%|███▋      | 184/500 [00:27<00:47,  6.62it/s]\u001b[A\n",
      " 37%|███▋      | 185/500 [00:27<00:47,  6.62it/s]\u001b[A\n",
      " 37%|███▋      | 186/500 [00:28<00:47,  6.62it/s]\u001b[A\n",
      " 37%|███▋      | 187/500 [00:28<00:47,  6.62it/s]\u001b[A\n",
      " 38%|███▊      | 188/500 [00:28<00:47,  6.63it/s]\u001b[A\n",
      " 38%|███▊      | 189/500 [00:28<00:46,  6.63it/s]\u001b[A\n",
      " 38%|███▊      | 190/500 [00:28<00:46,  6.62it/s]\u001b[A\n",
      " 38%|███▊      | 191/500 [00:28<00:46,  6.62it/s]\u001b[A\n",
      " 38%|███▊      | 192/500 [00:28<00:46,  6.62it/s]\u001b[A\n",
      " 39%|███▊      | 193/500 [00:29<00:46,  6.62it/s]\u001b[A\n",
      " 39%|███▉      | 194/500 [00:29<00:46,  6.62it/s]\u001b[A\n",
      " 39%|███▉      | 195/500 [00:29<00:46,  6.63it/s]\u001b[A\n",
      " 39%|███▉      | 196/500 [00:29<00:45,  6.63it/s]\u001b[A\n",
      " 39%|███▉      | 197/500 [00:29<00:45,  6.63it/s]\u001b[A\n",
      " 40%|███▉      | 198/500 [00:29<00:45,  6.63it/s]\u001b[A\n",
      " 40%|███▉      | 199/500 [00:30<00:45,  6.63it/s]\u001b[A\n",
      " 40%|████      | 200/500 [00:30<00:45,  6.63it/s]\u001b[A\n",
      " 40%|████      | 201/500 [00:30<00:45,  6.62it/s]\u001b[A\n",
      " 40%|████      | 202/500 [00:30<00:44,  6.62it/s]\u001b[A\n",
      " 41%|████      | 203/500 [00:30<00:44,  6.62it/s]\u001b[A\n",
      " 41%|████      | 204/500 [00:30<00:44,  6.62it/s]\u001b[A\n",
      " 41%|████      | 205/500 [00:30<00:44,  6.62it/s]\u001b[A\n",
      " 41%|████      | 206/500 [00:31<00:44,  6.62it/s]\u001b[A\n",
      " 41%|████▏     | 207/500 [00:31<00:44,  6.62it/s]\u001b[A\n",
      " 42%|████▏     | 208/500 [00:31<00:44,  6.62it/s]\u001b[A\n",
      " 42%|████▏     | 209/500 [00:31<00:43,  6.62it/s]\u001b[A\n",
      " 42%|████▏     | 210/500 [00:31<00:43,  6.62it/s]\u001b[A\n",
      " 42%|████▏     | 211/500 [00:31<00:43,  6.62it/s]\u001b[A\n",
      " 42%|████▏     | 212/500 [00:32<00:43,  6.62it/s]\u001b[A\n",
      " 43%|████▎     | 213/500 [00:32<00:43,  6.62it/s]\u001b[A\n",
      " 43%|████▎     | 214/500 [00:32<00:43,  6.62it/s]\u001b[A\n",
      " 43%|████▎     | 215/500 [00:32<00:43,  6.62it/s]\u001b[A\n",
      " 43%|████▎     | 216/500 [00:32<00:42,  6.62it/s]\u001b[A\n",
      " 43%|████▎     | 217/500 [00:32<00:42,  6.62it/s]\u001b[A\n",
      " 44%|████▎     | 218/500 [00:32<00:42,  6.62it/s]\u001b[A\n",
      " 44%|████▍     | 219/500 [00:33<00:42,  6.62it/s]\u001b[A\n",
      " 44%|████▍     | 220/500 [00:33<00:42,  6.62it/s]\u001b[A\n",
      " 44%|████▍     | 221/500 [00:33<00:42,  6.62it/s]\u001b[A\n",
      " 44%|████▍     | 222/500 [00:33<00:41,  6.62it/s]\u001b[A\n",
      " 45%|████▍     | 223/500 [00:33<00:41,  6.62it/s]\u001b[A\n",
      " 45%|████▍     | 224/500 [00:33<00:41,  6.62it/s]\u001b[A\n",
      " 45%|████▌     | 225/500 [00:33<00:41,  6.62it/s]\u001b[A\n",
      " 45%|████▌     | 226/500 [00:34<00:41,  6.62it/s]\u001b[A\n",
      " 45%|████▌     | 227/500 [00:34<00:41,  6.62it/s]\u001b[A\n",
      " 46%|████▌     | 228/500 [00:34<00:41,  6.62it/s]\u001b[A\n",
      " 46%|████▌     | 229/500 [00:34<00:40,  6.62it/s]\u001b[A\n",
      " 46%|████▌     | 230/500 [00:34<00:40,  6.62it/s]\u001b[A\n",
      " 46%|████▌     | 231/500 [00:34<00:40,  6.62it/s]\u001b[A\n",
      " 46%|████▋     | 232/500 [00:35<00:40,  6.62it/s]\u001b[A\n",
      " 47%|████▋     | 233/500 [00:35<00:40,  6.62it/s]\u001b[A\n",
      " 47%|████▋     | 234/500 [00:35<00:40,  6.62it/s]\u001b[A\n",
      " 47%|████▋     | 235/500 [00:35<00:40,  6.62it/s]\u001b[A\n",
      " 47%|████▋     | 236/500 [00:35<00:39,  6.62it/s]\u001b[A\n",
      " 47%|████▋     | 237/500 [00:35<00:39,  6.62it/s]\u001b[A\n",
      " 48%|████▊     | 238/500 [00:35<00:39,  6.62it/s]\u001b[A\n",
      " 48%|████▊     | 239/500 [00:36<00:39,  6.62it/s]\u001b[A\n",
      " 48%|████▊     | 240/500 [00:36<00:39,  6.62it/s]\u001b[A\n",
      " 48%|████▊     | 241/500 [00:36<00:39,  6.62it/s]\u001b[A\n",
      " 48%|████▊     | 242/500 [00:36<00:38,  6.62it/s]\u001b[A\n",
      " 49%|████▊     | 243/500 [00:36<00:38,  6.62it/s]\u001b[A\n",
      " 49%|████▉     | 244/500 [00:36<00:38,  6.62it/s]\u001b[A\n",
      " 49%|████▉     | 245/500 [00:37<00:38,  6.62it/s]\u001b[A\n",
      " 49%|████▉     | 246/500 [00:37<00:38,  6.62it/s]\u001b[A\n",
      " 49%|████▉     | 247/500 [00:37<00:38,  6.62it/s]\u001b[A\n",
      " 50%|████▉     | 248/500 [00:37<00:38,  6.62it/s]\u001b[A\n",
      " 50%|████▉     | 249/500 [00:37<00:37,  6.62it/s]\u001b[A\n",
      " 50%|█████     | 250/500 [00:37<00:37,  6.62it/s]\u001b[A\n",
      " 50%|█████     | 251/500 [00:37<00:37,  6.62it/s]\u001b[A\n",
      " 50%|█████     | 252/500 [00:38<00:37,  6.62it/s]\u001b[A\n",
      " 51%|█████     | 253/500 [00:38<00:37,  6.62it/s]\u001b[A\n",
      " 51%|█████     | 254/500 [00:38<00:37,  6.62it/s]\u001b[A\n",
      " 51%|█████     | 255/500 [00:38<00:37,  6.62it/s]\u001b[A\n",
      " 51%|█████     | 256/500 [00:38<00:36,  6.62it/s]\u001b[A\n",
      " 51%|█████▏    | 257/500 [00:38<00:36,  6.62it/s]\u001b[A\n",
      " 52%|█████▏    | 258/500 [00:38<00:36,  6.62it/s]\u001b[A\n",
      " 52%|█████▏    | 259/500 [00:39<00:36,  6.62it/s]\u001b[A\n",
      " 52%|█████▏    | 260/500 [00:39<00:36,  6.62it/s]\u001b[A\n",
      " 52%|█████▏    | 261/500 [00:39<00:36,  6.62it/s]\u001b[A\n",
      " 52%|█████▏    | 262/500 [00:39<00:35,  6.62it/s]\u001b[A\n",
      " 53%|█████▎    | 263/500 [00:39<00:35,  6.62it/s]\u001b[A\n",
      " 53%|█████▎    | 264/500 [00:39<00:35,  6.62it/s]\u001b[A\n",
      " 53%|█████▎    | 265/500 [00:40<00:35,  6.62it/s]\u001b[A\n",
      " 53%|█████▎    | 266/500 [00:40<00:35,  6.62it/s]\u001b[A\n",
      " 53%|█████▎    | 267/500 [00:40<00:35,  6.62it/s]\u001b[A\n",
      " 54%|█████▎    | 268/500 [00:40<00:35,  6.62it/s]\u001b[A\n",
      " 54%|█████▍    | 269/500 [00:40<00:34,  6.62it/s]\u001b[A\n",
      " 54%|█████▍    | 270/500 [00:40<00:34,  6.62it/s]\u001b[A\n",
      " 54%|█████▍    | 271/500 [00:40<00:34,  6.62it/s]\u001b[A\n",
      " 54%|█████▍    | 272/500 [00:41<00:34,  6.62it/s]\u001b[A\n",
      " 55%|█████▍    | 273/500 [00:41<00:34,  6.62it/s]\u001b[A\n",
      " 55%|█████▍    | 274/500 [00:41<00:34,  6.62it/s]\u001b[A\n",
      " 55%|█████▌    | 275/500 [00:41<00:33,  6.62it/s]\u001b[A\n",
      " 55%|█████▌    | 276/500 [00:41<00:33,  6.62it/s]\u001b[A\n",
      " 55%|█████▌    | 277/500 [00:41<00:33,  6.62it/s]\u001b[A\n",
      " 56%|█████▌    | 278/500 [00:41<00:33,  6.62it/s]\u001b[A\n",
      " 56%|█████▌    | 279/500 [00:42<00:33,  6.62it/s]\u001b[A\n",
      " 56%|█████▌    | 280/500 [00:42<00:33,  6.62it/s]\u001b[A\n",
      " 56%|█████▌    | 281/500 [00:42<00:33,  6.62it/s]\u001b[A\n",
      " 56%|█████▋    | 282/500 [00:42<00:32,  6.62it/s]\u001b[A\n",
      " 57%|█████▋    | 283/500 [00:42<00:32,  6.62it/s]\u001b[A\n",
      " 57%|█████▋    | 284/500 [00:42<00:32,  6.62it/s]\u001b[A\n",
      " 57%|█████▋    | 285/500 [00:43<00:32,  6.62it/s]\u001b[A\n",
      " 57%|█████▋    | 286/500 [00:43<00:32,  6.62it/s]\u001b[A\n",
      " 57%|█████▋    | 287/500 [00:43<00:32,  6.62it/s]\u001b[A\n",
      " 58%|█████▊    | 288/500 [00:43<00:32,  6.62it/s]\u001b[A\n",
      " 58%|█████▊    | 289/500 [00:43<00:31,  6.62it/s]\u001b[A\n",
      " 58%|█████▊    | 290/500 [00:43<00:31,  6.62it/s]\u001b[A\n",
      " 58%|█████▊    | 291/500 [00:43<00:31,  6.62it/s]\u001b[A\n",
      " 58%|█████▊    | 292/500 [00:44<00:31,  6.62it/s]\u001b[A\n",
      " 59%|█████▊    | 293/500 [00:44<00:31,  6.62it/s]\u001b[A\n",
      " 59%|█████▉    | 294/500 [00:44<00:31,  6.62it/s]\u001b[A\n",
      " 59%|█████▉    | 295/500 [00:44<00:30,  6.62it/s]\u001b[A\n",
      " 59%|█████▉    | 296/500 [00:44<00:30,  6.62it/s]\u001b[A\n",
      " 59%|█████▉    | 297/500 [00:44<00:30,  6.62it/s]\u001b[A\n",
      " 60%|█████▉    | 298/500 [00:45<00:30,  6.62it/s]\u001b[A\n",
      " 60%|█████▉    | 299/500 [00:45<00:30,  6.62it/s]\u001b[A\n",
      " 60%|██████    | 300/500 [00:45<00:30,  6.62it/s]\u001b[A\n",
      " 60%|██████    | 301/500 [00:45<00:30,  6.62it/s]\u001b[A\n",
      " 60%|██████    | 302/500 [00:45<00:29,  6.62it/s]\u001b[A\n",
      " 61%|██████    | 303/500 [00:45<00:29,  6.62it/s]\u001b[A\n",
      " 61%|██████    | 304/500 [00:45<00:29,  6.62it/s]\u001b[A\n",
      " 61%|██████    | 305/500 [00:46<00:29,  6.62it/s]\u001b[A\n",
      " 61%|██████    | 306/500 [00:46<00:29,  6.62it/s]\u001b[A\n",
      " 61%|██████▏   | 307/500 [00:46<00:29,  6.62it/s]\u001b[A\n",
      " 62%|██████▏   | 308/500 [00:46<00:29,  6.62it/s]\u001b[A\n",
      " 62%|██████▏   | 309/500 [00:46<00:28,  6.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/500 [00:46<00:28,  6.62it/s]\u001b[A\n",
      " 62%|██████▏   | 311/500 [00:46<00:28,  6.62it/s]\u001b[A\n",
      " 62%|██████▏   | 312/500 [00:47<00:28,  6.62it/s]\u001b[A\n",
      " 63%|██████▎   | 313/500 [00:47<00:28,  6.62it/s]\u001b[A\n",
      " 63%|██████▎   | 314/500 [00:47<00:28,  6.62it/s]\u001b[A\n",
      " 63%|██████▎   | 315/500 [00:47<00:27,  6.62it/s]\u001b[A\n",
      " 63%|██████▎   | 316/500 [00:47<00:27,  6.62it/s]\u001b[A\n",
      " 63%|██████▎   | 317/500 [00:47<00:27,  6.62it/s]\u001b[A\n",
      " 64%|██████▎   | 318/500 [00:48<00:27,  6.62it/s]\u001b[A\n",
      " 64%|██████▍   | 319/500 [00:48<00:27,  6.62it/s]\u001b[A\n",
      " 64%|██████▍   | 320/500 [00:48<00:27,  6.62it/s]\u001b[A\n",
      " 64%|██████▍   | 321/500 [00:48<00:27,  6.62it/s]\u001b[A\n",
      " 64%|██████▍   | 322/500 [00:48<00:26,  6.62it/s]\u001b[A\n",
      " 65%|██████▍   | 323/500 [00:48<00:26,  6.62it/s]\u001b[A\n",
      " 65%|██████▍   | 324/500 [00:48<00:26,  6.62it/s]\u001b[A\n",
      " 65%|██████▌   | 325/500 [00:49<00:26,  6.62it/s]\u001b[A\n",
      " 65%|██████▌   | 326/500 [00:49<00:26,  6.62it/s]\u001b[A\n",
      " 65%|██████▌   | 327/500 [00:49<00:26,  6.62it/s]\u001b[A\n",
      " 66%|██████▌   | 328/500 [00:49<00:25,  6.62it/s]\u001b[A\n",
      " 66%|██████▌   | 329/500 [00:49<00:25,  6.62it/s]\u001b[A\n",
      " 66%|██████▌   | 330/500 [00:49<00:25,  6.62it/s]\u001b[A\n",
      " 66%|██████▌   | 331/500 [00:50<00:25,  6.62it/s]\u001b[A\n",
      " 66%|██████▋   | 332/500 [00:50<00:25,  6.62it/s]\u001b[A\n",
      " 67%|██████▋   | 333/500 [00:50<00:25,  6.62it/s]\u001b[A\n",
      " 67%|██████▋   | 334/500 [00:50<00:25,  6.62it/s]\u001b[A\n",
      " 67%|██████▋   | 335/500 [00:50<00:24,  6.61it/s]\u001b[A\n",
      " 67%|██████▋   | 336/500 [00:50<00:24,  6.61it/s]\u001b[A\n",
      " 67%|██████▋   | 337/500 [00:50<00:24,  6.61it/s]\u001b[A\n",
      " 68%|██████▊   | 338/500 [00:51<00:24,  6.61it/s]\u001b[A\n",
      " 68%|██████▊   | 339/500 [00:51<00:24,  6.61it/s]\u001b[A\n",
      " 68%|██████▊   | 340/500 [00:51<00:24,  6.61it/s]\u001b[A\n",
      " 68%|██████▊   | 341/500 [00:51<00:24,  6.61it/s]\u001b[A\n",
      " 68%|██████▊   | 342/500 [00:51<00:23,  6.61it/s]\u001b[A\n",
      " 69%|██████▊   | 343/500 [00:51<00:23,  6.61it/s]\u001b[A\n",
      " 69%|██████▉   | 344/500 [00:52<00:23,  6.61it/s]\u001b[A\n",
      " 69%|██████▉   | 345/500 [00:52<00:23,  6.61it/s]\u001b[A\n",
      " 69%|██████▉   | 346/500 [00:52<00:23,  6.61it/s]\u001b[A\n",
      " 69%|██████▉   | 347/500 [00:52<00:23,  6.61it/s]\u001b[A\n",
      " 70%|██████▉   | 348/500 [00:52<00:22,  6.61it/s]\u001b[A\n",
      " 70%|██████▉   | 349/500 [00:52<00:22,  6.61it/s]\u001b[A\n",
      " 70%|███████   | 350/500 [00:52<00:22,  6.61it/s]\u001b[A\n",
      " 70%|███████   | 351/500 [00:53<00:22,  6.61it/s]\u001b[A\n",
      " 70%|███████   | 352/500 [00:53<00:22,  6.61it/s]\u001b[A\n",
      " 71%|███████   | 353/500 [00:53<00:22,  6.61it/s]\u001b[A\n",
      " 71%|███████   | 354/500 [00:53<00:22,  6.61it/s]\u001b[A\n",
      " 71%|███████   | 355/500 [00:53<00:21,  6.61it/s]\u001b[A\n",
      " 71%|███████   | 356/500 [00:53<00:21,  6.61it/s]\u001b[A\n",
      " 71%|███████▏  | 357/500 [00:53<00:21,  6.61it/s]\u001b[A\n",
      " 72%|███████▏  | 358/500 [00:54<00:21,  6.61it/s]\u001b[A\n",
      " 72%|███████▏  | 359/500 [00:54<00:21,  6.61it/s]\u001b[A\n",
      " 72%|███████▏  | 360/500 [00:54<00:21,  6.61it/s]\u001b[A\n",
      " 72%|███████▏  | 361/500 [00:54<00:21,  6.61it/s]\u001b[A\n",
      " 72%|███████▏  | 362/500 [00:54<00:20,  6.61it/s]\u001b[A\n",
      " 73%|███████▎  | 363/500 [00:54<00:20,  6.61it/s]\u001b[A\n",
      " 73%|███████▎  | 364/500 [00:55<00:20,  6.61it/s]\u001b[A\n",
      " 73%|███████▎  | 365/500 [00:55<00:20,  6.61it/s]\u001b[A\n",
      " 73%|███████▎  | 366/500 [00:55<00:20,  6.61it/s]\u001b[A\n",
      " 73%|███████▎  | 367/500 [00:55<00:20,  6.61it/s]\u001b[A\n",
      " 74%|███████▎  | 368/500 [00:55<00:19,  6.61it/s]\u001b[A\n",
      " 74%|███████▍  | 369/500 [00:55<00:19,  6.61it/s]\u001b[A\n",
      " 74%|███████▍  | 370/500 [00:55<00:19,  6.61it/s]\u001b[A\n",
      " 74%|███████▍  | 371/500 [00:56<00:19,  6.61it/s]\u001b[A\n",
      " 74%|███████▍  | 372/500 [00:56<00:19,  6.61it/s]\u001b[A\n",
      " 75%|███████▍  | 373/500 [00:56<00:19,  6.61it/s]\u001b[A\n",
      " 75%|███████▍  | 374/500 [00:56<00:19,  6.61it/s]\u001b[A\n",
      " 75%|███████▌  | 375/500 [00:56<00:18,  6.61it/s]\u001b[A\n",
      " 75%|███████▌  | 376/500 [00:56<00:18,  6.61it/s]\u001b[A\n",
      " 75%|███████▌  | 377/500 [00:57<00:18,  6.61it/s]\u001b[A\n",
      " 76%|███████▌  | 378/500 [00:57<00:18,  6.61it/s]\u001b[A\n",
      " 76%|███████▌  | 379/500 [00:57<00:18,  6.61it/s]\u001b[A\n",
      " 76%|███████▌  | 380/500 [00:57<00:18,  6.61it/s]\u001b[A\n",
      " 76%|███████▌  | 381/500 [00:57<00:18,  6.61it/s]\u001b[A\n",
      " 76%|███████▋  | 382/500 [00:57<00:17,  6.61it/s]\u001b[A\n",
      " 77%|███████▋  | 383/500 [00:57<00:17,  6.61it/s]\u001b[A\n",
      " 77%|███████▋  | 384/500 [00:58<00:17,  6.61it/s]\u001b[A\n",
      " 77%|███████▋  | 385/500 [00:58<00:17,  6.61it/s]\u001b[A\n",
      " 77%|███████▋  | 386/500 [00:58<00:17,  6.61it/s]\u001b[A\n",
      " 77%|███████▋  | 387/500 [00:58<00:17,  6.61it/s]\u001b[A\n",
      " 78%|███████▊  | 388/500 [00:58<00:16,  6.61it/s]\u001b[A\n",
      " 78%|███████▊  | 389/500 [00:58<00:16,  6.61it/s]\u001b[A\n",
      " 78%|███████▊  | 390/500 [00:59<00:16,  6.61it/s]\u001b[A\n",
      " 78%|███████▊  | 391/500 [00:59<00:16,  6.61it/s]\u001b[A\n",
      " 78%|███████▊  | 392/500 [00:59<00:16,  6.61it/s]\u001b[A\n",
      " 79%|███████▊  | 393/500 [00:59<00:16,  6.61it/s]\u001b[A\n",
      " 79%|███████▉  | 394/500 [00:59<00:16,  6.61it/s]\u001b[A\n",
      " 79%|███████▉  | 395/500 [00:59<00:15,  6.61it/s]\u001b[A\n",
      " 79%|███████▉  | 396/500 [00:59<00:15,  6.61it/s]\u001b[A\n",
      " 79%|███████▉  | 397/500 [01:00<00:15,  6.61it/s]\u001b[A\n",
      " 80%|███████▉  | 398/500 [01:00<00:15,  6.61it/s]\u001b[A\n",
      " 80%|███████▉  | 399/500 [01:00<00:15,  6.61it/s]\u001b[A\n",
      " 80%|████████  | 400/500 [01:00<00:15,  6.61it/s]\u001b[A\n",
      " 80%|████████  | 401/500 [01:00<00:14,  6.61it/s]\u001b[A\n",
      " 80%|████████  | 402/500 [01:00<00:14,  6.61it/s]\u001b[A\n",
      " 81%|████████  | 403/500 [01:00<00:14,  6.61it/s]\u001b[A\n",
      " 81%|████████  | 404/500 [01:01<00:14,  6.61it/s]\u001b[A\n",
      " 81%|████████  | 405/500 [01:01<00:14,  6.61it/s]\u001b[A\n",
      " 81%|████████  | 406/500 [01:01<00:14,  6.61it/s]\u001b[A\n",
      " 81%|████████▏ | 407/500 [01:01<00:14,  6.61it/s]\u001b[A\n",
      " 82%|████████▏ | 408/500 [01:01<00:13,  6.61it/s]\u001b[A\n",
      " 82%|████████▏ | 409/500 [01:01<00:13,  6.61it/s]\u001b[A\n",
      " 82%|████████▏ | 410/500 [01:02<00:13,  6.61it/s]\u001b[A\n",
      " 82%|████████▏ | 411/500 [01:02<00:13,  6.61it/s]\u001b[A\n",
      " 82%|████████▏ | 412/500 [01:02<00:13,  6.61it/s]\u001b[A\n",
      " 83%|████████▎ | 413/500 [01:02<00:13,  6.61it/s]\u001b[A\n",
      " 83%|████████▎ | 414/500 [01:02<00:13,  6.61it/s]\u001b[A\n",
      " 83%|████████▎ | 415/500 [01:02<00:12,  6.61it/s]\u001b[A\n",
      " 83%|████████▎ | 416/500 [01:02<00:12,  6.61it/s]\u001b[A\n",
      " 83%|████████▎ | 417/500 [01:03<00:12,  6.61it/s]\u001b[A\n",
      " 84%|████████▎ | 418/500 [01:03<00:12,  6.61it/s]\u001b[A\n",
      " 84%|████████▍ | 419/500 [01:03<00:12,  6.61it/s]\u001b[A\n",
      " 84%|████████▍ | 420/500 [01:03<00:12,  6.61it/s]\u001b[A\n",
      " 84%|████████▍ | 421/500 [01:03<00:11,  6.61it/s]\u001b[A\n",
      " 84%|████████▍ | 422/500 [01:03<00:11,  6.61it/s]\u001b[A\n",
      " 85%|████████▍ | 423/500 [01:04<00:11,  6.60it/s]\u001b[A\n",
      " 85%|████████▍ | 424/500 [01:04<00:11,  6.60it/s]\u001b[A\n",
      " 85%|████████▌ | 425/500 [01:04<00:11,  6.60it/s]\u001b[A\n",
      " 85%|████████▌ | 426/500 [01:04<00:11,  6.60it/s]\u001b[A\n",
      " 85%|████████▌ | 427/500 [01:04<00:11,  6.60it/s]\u001b[A\n",
      " 86%|████████▌ | 428/500 [01:04<00:10,  6.60it/s]\u001b[A\n",
      " 86%|████████▌ | 429/500 [01:04<00:10,  6.60it/s]\u001b[A\n",
      " 86%|████████▌ | 430/500 [01:05<00:10,  6.60it/s]\u001b[A\n",
      " 86%|████████▌ | 431/500 [01:05<00:10,  6.60it/s]\u001b[A\n",
      " 86%|████████▋ | 432/500 [01:05<00:10,  6.60it/s]\u001b[A\n",
      " 87%|████████▋ | 433/500 [01:05<00:10,  6.60it/s]\u001b[A\n",
      " 87%|████████▋ | 434/500 [01:05<00:09,  6.60it/s]\u001b[A\n",
      " 87%|████████▋ | 435/500 [01:05<00:09,  6.60it/s]\u001b[A\n",
      " 87%|████████▋ | 436/500 [01:06<00:09,  6.60it/s]\u001b[A\n",
      " 87%|████████▋ | 437/500 [01:06<00:09,  6.60it/s]\u001b[A\n",
      " 88%|████████▊ | 438/500 [01:06<00:09,  6.60it/s]\u001b[A\n",
      " 88%|████████▊ | 439/500 [01:06<00:09,  6.60it/s]\u001b[A\n",
      " 88%|████████▊ | 440/500 [01:06<00:09,  6.60it/s]\u001b[A\n",
      " 88%|████████▊ | 441/500 [01:06<00:08,  6.60it/s]\u001b[A\n",
      " 88%|████████▊ | 442/500 [01:06<00:08,  6.60it/s]\u001b[A\n",
      " 89%|████████▊ | 443/500 [01:07<00:08,  6.60it/s]\u001b[A\n",
      " 89%|████████▉ | 444/500 [01:07<00:08,  6.60it/s]\u001b[A\n",
      " 89%|████████▉ | 445/500 [01:07<00:08,  6.60it/s]\u001b[A\n",
      " 89%|████████▉ | 446/500 [01:07<00:08,  6.60it/s]\u001b[A\n",
      " 89%|████████▉ | 447/500 [01:07<00:08,  6.60it/s]\u001b[A\n",
      " 90%|████████▉ | 448/500 [01:07<00:07,  6.60it/s]\u001b[A\n",
      " 90%|████████▉ | 449/500 [01:08<00:07,  6.60it/s]\u001b[A\n",
      " 90%|█████████ | 450/500 [01:08<00:07,  6.60it/s]\u001b[A\n",
      " 90%|█████████ | 451/500 [01:08<00:07,  6.60it/s]\u001b[A\n",
      " 90%|█████████ | 452/500 [01:08<00:07,  6.60it/s]\u001b[A\n",
      " 91%|█████████ | 453/500 [01:08<00:07,  6.60it/s]\u001b[A\n",
      " 91%|█████████ | 454/500 [01:08<00:06,  6.60it/s]\u001b[A\n",
      " 91%|█████████ | 455/500 [01:08<00:06,  6.60it/s]\u001b[A\n",
      " 91%|█████████ | 456/500 [01:09<00:06,  6.60it/s]\u001b[A\n",
      " 91%|█████████▏| 457/500 [01:09<00:06,  6.60it/s]\u001b[A\n",
      " 92%|█████████▏| 458/500 [01:09<00:06,  6.60it/s]\u001b[A\n",
      " 92%|█████████▏| 459/500 [01:09<00:06,  6.60it/s]\u001b[A\n",
      " 92%|█████████▏| 460/500 [01:09<00:06,  6.60it/s]\u001b[A\n",
      " 92%|█████████▏| 461/500 [01:09<00:05,  6.60it/s]\u001b[A\n",
      " 92%|█████████▏| 462/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 93%|█████████▎| 463/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 93%|█████████▎| 464/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 93%|█████████▎| 465/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 93%|█████████▎| 466/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 93%|█████████▎| 467/500 [01:10<00:05,  6.60it/s]\u001b[A\n",
      " 94%|█████████▎| 468/500 [01:10<00:04,  6.60it/s]\u001b[A\n",
      " 94%|█████████▍| 469/500 [01:11<00:04,  6.60it/s]\u001b[A\n",
      " 94%|█████████▍| 470/500 [01:11<00:04,  6.60it/s]\u001b[A\n",
      " 94%|█████████▍| 471/500 [01:11<00:04,  6.60it/s]\u001b[A\n",
      " 94%|█████████▍| 472/500 [01:11<00:04,  6.60it/s]\u001b[A\n",
      " 95%|█████████▍| 473/500 [01:11<00:04,  6.60it/s]\u001b[A\n",
      " 95%|█████████▍| 474/500 [01:11<00:03,  6.60it/s]\u001b[A\n",
      " 95%|█████████▌| 475/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 95%|█████████▌| 476/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 95%|█████████▌| 477/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 96%|█████████▌| 478/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 96%|█████████▌| 479/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 96%|█████████▌| 480/500 [01:12<00:03,  6.60it/s]\u001b[A\n",
      " 96%|█████████▌| 481/500 [01:12<00:02,  6.60it/s]\u001b[A\n",
      " 96%|█████████▋| 482/500 [01:13<00:02,  6.60it/s]\u001b[A\n",
      " 97%|█████████▋| 483/500 [01:13<00:02,  6.59it/s]\u001b[A\n",
      " 97%|█████████▋| 484/500 [01:13<00:02,  6.59it/s]\u001b[A\n",
      " 97%|█████████▋| 485/500 [01:13<00:02,  6.59it/s]\u001b[A\n",
      " 97%|█████████▋| 486/500 [01:13<00:02,  6.59it/s]\u001b[A\n",
      " 97%|█████████▋| 487/500 [01:13<00:01,  6.59it/s]\u001b[A\n",
      " 98%|█████████▊| 488/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 98%|█████████▊| 489/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 98%|█████████▊| 490/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 98%|█████████▊| 491/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 98%|█████████▊| 492/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 99%|█████████▊| 493/500 [01:14<00:01,  6.59it/s]\u001b[A\n",
      " 99%|█████████▉| 494/500 [01:14<00:00,  6.59it/s]\u001b[A\n",
      " 99%|█████████▉| 495/500 [01:15<00:00,  6.59it/s]\u001b[A\n",
      " 99%|█████████▉| 496/500 [01:15<00:00,  6.59it/s]\u001b[A\n",
      " 99%|█████████▉| 497/500 [01:15<00:00,  6.59it/s]\u001b[A\n",
      "100%|█████████▉| 498/500 [01:15<00:00,  6.59it/s]\u001b[A\n",
      "100%|█████████▉| 499/500 [01:15<00:00,  6.59it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# eval model\n",
    "val_ds = ds_fetcher(batch_size, data_root=data_root, train=False, input_size=input_size)\n",
    "acc1, acc5 = misc.eval_model(model_raw, val_ds, ngpu=ngpu, is_imagenet=is_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55948, 0.7913)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the accuracy at fp32\n",
    "acc1, acc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect activation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Logger, self).__init__()\n",
    "        self.name = name\n",
    "        self.log_items = []\n",
    "        #self.percentiles = torch.zeros(1, 5).cuda()\n",
    "        #self.indices = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Slowwwwwww (7s/it)\n",
    "        #log_item = np.percentile(x.data.cpu().numpy(), q=[float(x) for x in [0, 5, 95, 100]])\n",
    "        # (~4.9it/s)\n",
    "        #log_item = (torch.min(x).data.cpu().numpy()[0],\n",
    "        #            torch.max(x).data.cpu().numpy()[0])\n",
    "        # histc not implemented on cuda\n",
    "        #log_item = torch.histc(x, bins=100).cpu().numpy()\n",
    "        \n",
    "        #if self.indices is None:\n",
    "        #    length = x.data.view(-1).size()[0]\n",
    "        #    self.indices = torch.LongTensor([int(float(p)/1000*length) for p in range(0,1001)]).cuda()\n",
    "        \n",
    "        sorted, _indices = torch.sort(x.data.view(-1))\n",
    "        #prow = torch.index_select(sorted, 0, self.indices)\n",
    "        #self.percentiles = torch.cat((self.percentiles, prow))\n",
    "        #del sorted\n",
    "        #del prow\n",
    "        \n",
    "        \n",
    "        self.log_items.append(log_item)\n",
    "        return x\n",
    "    \n",
    "import copy\n",
    "def duplicate_model_with_logging(model, indent_level=0):\n",
    "    \"\"\"\n",
    "    Inserts logging nodes into a NN model.\n",
    "    \n",
    "    Assumes that original model has at least a nn.Sequential.\n",
    "    \"\"\"\n",
    "    loggers = []\n",
    "    indent = \" \" * indent_level\n",
    "    if isinstance(model, nn.Sequential):\n",
    "        print(f'{indent}Sequential')\n",
    "        l = OrderedDict()\n",
    "        if indent_level == 0:\n",
    "            l[\"input_log\"] = Logger(\"input\")\n",
    "        for k, v in model._modules.items():\n",
    "            print(f'{indent} Looking at : {k}')\n",
    "            if isinstance(v, (nn.Conv2d, nn.Linear, nn.BatchNorm1d, nn.BatchNorm2d, nn.AvgPool2d)):\n",
    "                l[k] = v\n",
    "                logger = Logger(k)\n",
    "                l[f'{k}_log'] = logger\n",
    "                loggers.append(logger)\n",
    "            else:\n",
    "                l[k], subloggers = duplicate_model_with_logging(v, indent_level + 1)\n",
    "                loggers.extend(subloggers)\n",
    "        m = nn.Sequential(l)\n",
    "        return m, loggers\n",
    "    else:\n",
    "        print(f'{indent}Not Sequential')\n",
    "        model = model #if indent_level > 0 else copy.deepcopy(model)\n",
    "        for k, v in model._modules.items():\n",
    "            model._modules[k], subloggers = duplicate_model_with_logging(v)\n",
    "            loggers.extend(subloggers)\n",
    "        return model, loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Sequential\n",
      "Sequential\n",
      " Looking at : 0\n",
      " Looking at : 1\n",
      " Not Sequential\n",
      " Looking at : 2\n",
      " Not Sequential\n",
      " Looking at : 3\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 4\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 5\n",
      " Not Sequential\n",
      " Looking at : 6\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 7\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 8\n",
      " Not Sequential\n",
      " Looking at : 9\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 10\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 11\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      " Looking at : 12\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : squeeze\n",
      " Looking at : squeeze_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand1x1\n",
      " Looking at : expand1x1_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : expand3x3\n",
      " Looking at : expand3x3_activation\n",
      " Not Sequential\n",
      "Sequential\n",
      " Looking at : 0\n",
      " Not Sequential\n",
      " Looking at : 1\n",
      " Looking at : 2\n",
      " Not Sequential\n",
      " Looking at : 3\n"
     ]
    }
   ],
   "source": [
    "model_log, loggers = duplicate_model_with_logging(model_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Sequential\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/THC/THCTensorCopy.cu:100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-55024557a606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicate_model_with_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_fetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_imagenet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_imagenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f3b31b7c0145>\u001b[0m in \u001b[0;36mduplicate_model_with_logging\u001b[0;34m(model, indent_level)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{indent}Not Sequential'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindent_level\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubloggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicate_model_with_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise RuntimeError(\"Only Variables created explicitly by the user \"\n\u001b[1;32m     92\u001b[0m                                \"(graph leaves) support the deepcopy protocol at the moment\")\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/THC/THCTensorCopy.cu:100"
     ]
    }
   ],
   "source": [
    "val_ds = ds_fetcher(batch_size, data_root=data_root, train=False, input_size=input_size)\n",
    "acc1, acc5 = misc.eval_model(model_log, val_ds, ngpu=ngpu, is_imagenet=is_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'torch.nn.modules.module.Module'>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(nn.Module().__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff4f5d417b8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4f5d3c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sbs\n",
    "data = np.asarray(loggers[1].log_items)\n",
    "sbs.distplot(data[:,1] - data[:,0], hist=True, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-64.68961334,  37.50022125],\n",
       "       [-59.58321198,  37.99289818],\n",
       "       [-57.89531536,  39.38270359],\n",
       "       [-48.49136219,  49.74721947],\n",
       "       [-47.57300343,  51.59901909],\n",
       "       [-46.29519653,  56.11297226]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data, q=[0, 1, 5, 95, 99, 100], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b38d2e631899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "[0,1,2,3,4,5][[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying for quantised inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.Fire'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.AvgPool2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'imagenet.squeezenet.SqueezeNet'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (3): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (9): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (group1): Sequential(\n",
       "        (squeeze): Conv2d (512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (squeeze_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group2): Sequential(\n",
       "        (expand1x1): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (expand1x1_activation): ReLU(inplace)\n",
       "      )\n",
       "      (group3): Sequential(\n",
       "        (expand3x3): Conv2d (64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (expand3x3_activation): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Conv2d (512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace)\n",
       "    (3): AvgPool2d(kernel_size=13, stride=13, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.apply(f) calls f for each Module in the model.\n",
    "#  But it doesn't handle things like torch.concat\n",
    "model_raw.apply(lambda m: print(type(m)))\n",
    "\n",
    "# Can copy a model with:\n",
    "import copy\n",
    "copy.deepcopy(model_raw)\n",
    "# Or just recreate the model:\n",
    "model_copy = create_model()\n",
    "model_copy.lead_state_dict(original_model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pickle object from /tmp/public_dataset/pytorch/imagenet-data/val224.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building IMAGENET data loader, 50000 for train, 50000 for test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> Done (6.3597 s)\n"
     ]
    }
   ],
   "source": [
    "val_ds = ds_fetcher(batch_size, data_root=data_root, train=False, input_size=input_size)\n",
    "(data, target) = next(val_ds)\n",
    "data = Variable(torch.FloatTensor(data)).cuda()\n",
    "model_cuda = torch.nn.DataParallel(model_raw.eval(), device_ids=range(ngpu)).cuda()\n",
    "trace, out = jit.trace(model_cuda, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%1 : Float(100, 3, 224, 224)\n",
       "      %2 : Float(64, 3, 3, 3)\n",
       "      %3 : Float(64)\n",
       "      %4 : Float(16, 64, 1, 1)\n",
       "      %5 : Float(16)\n",
       "      %6 : Float(64, 16, 1, 1)\n",
       "      %7 : Float(64)\n",
       "      %8 : Float(64, 16, 3, 3)\n",
       "      %9 : Float(64)\n",
       "      %10 : Float(16, 128, 1, 1)\n",
       "      %11 : Float(16)\n",
       "      %12 : Float(64, 16, 1, 1)\n",
       "      %13 : Float(64)\n",
       "      %14 : Float(64, 16, 3, 3)\n",
       "      %15 : Float(64)\n",
       "      %16 : Float(32, 128, 1, 1)\n",
       "      %17 : Float(32)\n",
       "      %18 : Float(128, 32, 1, 1)\n",
       "      %19 : Float(128)\n",
       "      %20 : Float(128, 32, 3, 3)\n",
       "      %21 : Float(128)\n",
       "      %22 : Float(32, 256, 1, 1)\n",
       "      %23 : Float(32)\n",
       "      %24 : Float(128, 32, 1, 1)\n",
       "      %25 : Float(128)\n",
       "      %26 : Float(128, 32, 3, 3)\n",
       "      %27 : Float(128)\n",
       "      %28 : Float(48, 256, 1, 1)\n",
       "      %29 : Float(48)\n",
       "      %30 : Float(192, 48, 1, 1)\n",
       "      %31 : Float(192)\n",
       "      %32 : Float(192, 48, 3, 3)\n",
       "      %33 : Float(192)\n",
       "      %34 : Float(48, 384, 1, 1)\n",
       "      %35 : Float(48)\n",
       "      %36 : Float(192, 48, 1, 1)\n",
       "      %37 : Float(192)\n",
       "      %38 : Float(192, 48, 3, 3)\n",
       "      %39 : Float(192)\n",
       "      %40 : Float(64, 384, 1, 1)\n",
       "      %41 : Float(64)\n",
       "      %42 : Float(256, 64, 1, 1)\n",
       "      %43 : Float(256)\n",
       "      %44 : Float(256, 64, 3, 3)\n",
       "      %45 : Float(256)\n",
       "      %46 : Float(64, 512, 1, 1)\n",
       "      %47 : Float(64)\n",
       "      %48 : Float(256, 64, 1, 1)\n",
       "      %49 : Float(256)\n",
       "      %50 : Float(256, 64, 3, 3)\n",
       "      %51 : Float(256)\n",
       "      %52 : Float(1000, 512, 1, 1)\n",
       "      %53 : Float(1000)) {\n",
       "  %55 : Float(100, 3, 224, 224), %56 : Handle = ^Scatter(range(0, 1), None, 0)(%1), uses = [[%57.i0], []];\n",
       "  %58 : Float(100, 64, 111, 111), %59 : Handle = CppOp[ConvForward](%55, %2, %3), uses = [[%60.i0], []];\n",
       "  %60 : Float(100, 64, 111, 111) = threshold[threshold={0}, value={0}, inplace=1](%58), uses = [%61.i0];\n",
       "  %62 : Float(100, 64, 55, 55), %63 : Long(100, 64, 55, 55) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%60), uses = [[%64.i0], []];\n",
       "  %65 : Float(100, 16, 55, 55), %66 : Handle = CppOp[ConvForward](%62, %4, %5), uses = [[%67.i0], []];\n",
       "  %67 : Float(100, 16, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%65), uses = [%68.i0, %72.i0];\n",
       "  %69 : Float(100, 64, 55, 55), %70 : Handle = CppOp[ConvForward](%67, %6, %7), uses = [[%71.i0], []];\n",
       "  %71 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%69), uses = [%76.i0];\n",
       "  %73 : Float(100, 64, 55, 55), %74 : Handle = CppOp[ConvForward](%67, %8, %9), uses = [[%75.i0], []];\n",
       "  %75 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%73), uses = [%76.i1];\n",
       "  %76 : Float(100, 128, 55, 55) = cat[dim=1](%71, %75), uses = [%77.i0];\n",
       "  %78 : Float(100, 16, 55, 55), %79 : Handle = CppOp[ConvForward](%76, %10, %11), uses = [[%80.i0], []];\n",
       "  %80 : Float(100, 16, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%78), uses = [%81.i0, %85.i0];\n",
       "  %82 : Float(100, 64, 55, 55), %83 : Handle = CppOp[ConvForward](%80, %12, %13), uses = [[%84.i0], []];\n",
       "  %84 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%82), uses = [%89.i0];\n",
       "  %86 : Float(100, 64, 55, 55), %87 : Handle = CppOp[ConvForward](%80, %14, %15), uses = [[%88.i0], []];\n",
       "  %88 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%86), uses = [%89.i1];\n",
       "  %89 : Float(100, 128, 55, 55) = cat[dim=1](%84, %88), uses = [%90.i0];\n",
       "  %91 : Float(100, 128, 27, 27), %92 : Long(100, 128, 27, 27) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%89), uses = [[%93.i0], []];\n",
       "  %94 : Float(100, 32, 27, 27), %95 : Handle = CppOp[ConvForward](%91, %16, %17), uses = [[%96.i0], []];\n",
       "  %96 : Float(100, 32, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%94), uses = [%97.i0, %101.i0];\n",
       "  %98 : Float(100, 128, 27, 27), %99 : Handle = CppOp[ConvForward](%96, %18, %19), uses = [[%100.i0], []];\n",
       "  %100 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%98), uses = [%105.i0];\n",
       "  %102 : Float(100, 128, 27, 27), %103 : Handle = CppOp[ConvForward](%96, %20, %21), uses = [[%104.i0], []];\n",
       "  %104 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%102), uses = [%105.i1];\n",
       "  %105 : Float(100, 256, 27, 27) = cat[dim=1](%100, %104), uses = [%106.i0];\n",
       "  %107 : Float(100, 32, 27, 27), %108 : Handle = CppOp[ConvForward](%105, %22, %23), uses = [[%109.i0], []];\n",
       "  %109 : Float(100, 32, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%107), uses = [%110.i0, %114.i0];\n",
       "  %111 : Float(100, 128, 27, 27), %112 : Handle = CppOp[ConvForward](%109, %24, %25), uses = [[%113.i0], []];\n",
       "  %113 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%111), uses = [%118.i0];\n",
       "  %115 : Float(100, 128, 27, 27), %116 : Handle = CppOp[ConvForward](%109, %26, %27), uses = [[%117.i0], []];\n",
       "  %117 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%115), uses = [%118.i1];\n",
       "  %118 : Float(100, 256, 27, 27) = cat[dim=1](%113, %117), uses = [%119.i0];\n",
       "  %120 : Float(100, 256, 13, 13), %121 : Long(100, 256, 13, 13) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%118), uses = [[%122.i0], []];\n",
       "  %123 : Float(100, 48, 13, 13), %124 : Handle = CppOp[ConvForward](%120, %28, %29), uses = [[%125.i0], []];\n",
       "  %125 : Float(100, 48, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%123), uses = [%126.i0, %130.i0];\n",
       "  %127 : Float(100, 192, 13, 13), %128 : Handle = CppOp[ConvForward](%125, %30, %31), uses = [[%129.i0], []];\n",
       "  %129 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%127), uses = [%134.i0];\n",
       "  %131 : Float(100, 192, 13, 13), %132 : Handle = CppOp[ConvForward](%125, %32, %33), uses = [[%133.i0], []];\n",
       "  %133 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%131), uses = [%134.i1];\n",
       "  %134 : Float(100, 384, 13, 13) = cat[dim=1](%129, %133), uses = [%135.i0];\n",
       "  %136 : Float(100, 48, 13, 13), %137 : Handle = CppOp[ConvForward](%134, %34, %35), uses = [[%138.i0], []];\n",
       "  %138 : Float(100, 48, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%136), uses = [%139.i0, %143.i0];\n",
       "  %140 : Float(100, 192, 13, 13), %141 : Handle = CppOp[ConvForward](%138, %36, %37), uses = [[%142.i0], []];\n",
       "  %142 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%140), uses = [%147.i0];\n",
       "  %144 : Float(100, 192, 13, 13), %145 : Handle = CppOp[ConvForward](%138, %38, %39), uses = [[%146.i0], []];\n",
       "  %146 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%144), uses = [%147.i1];\n",
       "  %147 : Float(100, 384, 13, 13) = cat[dim=1](%142, %146), uses = [%148.i0];\n",
       "  %149 : Float(100, 64, 13, 13), %150 : Handle = CppOp[ConvForward](%147, %40, %41), uses = [[%151.i0], []];\n",
       "  %151 : Float(100, 64, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%149), uses = [%152.i0, %156.i0];\n",
       "  %153 : Float(100, 256, 13, 13), %154 : Handle = CppOp[ConvForward](%151, %42, %43), uses = [[%155.i0], []];\n",
       "  %155 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%153), uses = [%160.i0];\n",
       "  %157 : Float(100, 256, 13, 13), %158 : Handle = CppOp[ConvForward](%151, %44, %45), uses = [[%159.i0], []];\n",
       "  %159 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%157), uses = [%160.i1];\n",
       "  %160 : Float(100, 512, 13, 13) = cat[dim=1](%155, %159), uses = [%161.i0];\n",
       "  %162 : Float(100, 64, 13, 13), %163 : Handle = CppOp[ConvForward](%160, %46, %47), uses = [[%164.i0], []];\n",
       "  %164 : Float(100, 64, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%162), uses = [%165.i0, %169.i0];\n",
       "  %166 : Float(100, 256, 13, 13), %167 : Handle = CppOp[ConvForward](%164, %48, %49), uses = [[%168.i0], []];\n",
       "  %168 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%166), uses = [%173.i0];\n",
       "  %170 : Float(100, 256, 13, 13), %171 : Handle = CppOp[ConvForward](%164, %50, %51), uses = [[%172.i0], []];\n",
       "  %172 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%170), uses = [%173.i1];\n",
       "  %173 : Float(100, 512, 13, 13) = cat[dim=1](%168, %172), uses = [%174.i0];\n",
       "  %175 : Float(100, 512, 13, 13), %176 : Handle = ^Dropout(0.5, False, False)(%173), uses = [[%177.i0], []];\n",
       "  %178 : Float(100, 1000, 13, 13), %179 : Handle = CppOp[ConvForward](%175, %52, %53), uses = [[%180.i0], []];\n",
       "  %180 : Float(100, 1000, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%178), uses = [%181.i0];\n",
       "  %181 : Float(100, 1000, 1, 1) = avg_pool2d[kernel_size=[13, 13], stride=[13, 13], padding=[0, 0], ceil_mode=0, count_include_pad=1](%180), uses = [%182.i0];\n",
       "  %182 : Float(100, 1000) = view[size=[100, 1000]](%181), uses = [%0.i0];\n",
       "  return (%182);\n",
       "}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%1 : Float(100, 3, 224, 224)\n",
      "      %2 : Float(64, 3, 3, 3)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(16, 64, 1, 1)\n",
      "      %5 : Float(16)\n",
      "      %6 : Float(64, 16, 1, 1)\n",
      "      %7 : Float(64)\n",
      "      %8 : Float(64, 16, 3, 3)\n",
      "      %9 : Float(64)\n",
      "      %10 : Float(16, 128, 1, 1)\n",
      "      %11 : Float(16)\n",
      "      %12 : Float(64, 16, 1, 1)\n",
      "      %13 : Float(64)\n",
      "      %14 : Float(64, 16, 3, 3)\n",
      "      %15 : Float(64)\n",
      "      %16 : Float(32, 128, 1, 1)\n",
      "      %17 : Float(32)\n",
      "      %18 : Float(128, 32, 1, 1)\n",
      "      %19 : Float(128)\n",
      "      %20 : Float(128, 32, 3, 3)\n",
      "      %21 : Float(128)\n",
      "      %22 : Float(32, 256, 1, 1)\n",
      "      %23 : Float(32)\n",
      "      %24 : Float(128, 32, 1, 1)\n",
      "      %25 : Float(128)\n",
      "      %26 : Float(128, 32, 3, 3)\n",
      "      %27 : Float(128)\n",
      "      %28 : Float(48, 256, 1, 1)\n",
      "      %29 : Float(48)\n",
      "      %30 : Float(192, 48, 1, 1)\n",
      "      %31 : Float(192)\n",
      "      %32 : Float(192, 48, 3, 3)\n",
      "      %33 : Float(192)\n",
      "      %34 : Float(48, 384, 1, 1)\n",
      "      %35 : Float(48)\n",
      "      %36 : Float(192, 48, 1, 1)\n",
      "      %37 : Float(192)\n",
      "      %38 : Float(192, 48, 3, 3)\n",
      "      %39 : Float(192)\n",
      "      %40 : Float(64, 384, 1, 1)\n",
      "      %41 : Float(64)\n",
      "      %42 : Float(256, 64, 1, 1)\n",
      "      %43 : Float(256)\n",
      "      %44 : Float(256, 64, 3, 3)\n",
      "      %45 : Float(256)\n",
      "      %46 : Float(64, 512, 1, 1)\n",
      "      %47 : Float(64)\n",
      "      %48 : Float(256, 64, 1, 1)\n",
      "      %49 : Float(256)\n",
      "      %50 : Float(256, 64, 3, 3)\n",
      "      %51 : Float(256)\n",
      "      %52 : Float(1000, 512, 1, 1)\n",
      "      %53 : Float(1000)) {\n",
      "  %55 : Float(100, 3, 224, 224), %56 : Handle = ^Scatter(range(0, 1), None, 0)(%1), uses = [[%57.i0], []];\n",
      "  %58 : Float(100, 64, 111, 111), %59 : Handle = CppOp[ConvForward](%55, %2, %3), uses = [[%60.i0], []];\n",
      "  %60 : Float(100, 64, 111, 111) = threshold[threshold={0}, value={0}, inplace=1](%58), uses = [%61.i0];\n",
      "  %62 : Float(100, 64, 55, 55), %63 : Long(100, 64, 55, 55) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%60), uses = [[%64.i0], []];\n",
      "  %65 : Float(100, 16, 55, 55), %66 : Handle = CppOp[ConvForward](%62, %4, %5), uses = [[%67.i0], []];\n",
      "  %67 : Float(100, 16, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%65), uses = [%68.i0, %72.i0];\n",
      "  %69 : Float(100, 64, 55, 55), %70 : Handle = CppOp[ConvForward](%67, %6, %7), uses = [[%71.i0], []];\n",
      "  %71 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%69), uses = [%76.i0];\n",
      "  %73 : Float(100, 64, 55, 55), %74 : Handle = CppOp[ConvForward](%67, %8, %9), uses = [[%75.i0], []];\n",
      "  %75 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%73), uses = [%76.i1];\n",
      "  %76 : Float(100, 128, 55, 55) = cat[dim=1](%71, %75), uses = [%77.i0];\n",
      "  %78 : Float(100, 16, 55, 55), %79 : Handle = CppOp[ConvForward](%76, %10, %11), uses = [[%80.i0], []];\n",
      "  %80 : Float(100, 16, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%78), uses = [%81.i0, %85.i0];\n",
      "  %82 : Float(100, 64, 55, 55), %83 : Handle = CppOp[ConvForward](%80, %12, %13), uses = [[%84.i0], []];\n",
      "  %84 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%82), uses = [%89.i0];\n",
      "  %86 : Float(100, 64, 55, 55), %87 : Handle = CppOp[ConvForward](%80, %14, %15), uses = [[%88.i0], []];\n",
      "  %88 : Float(100, 64, 55, 55) = threshold[threshold={0}, value={0}, inplace=1](%86), uses = [%89.i1];\n",
      "  %89 : Float(100, 128, 55, 55) = cat[dim=1](%84, %88), uses = [%90.i0];\n",
      "  %91 : Float(100, 128, 27, 27), %92 : Long(100, 128, 27, 27) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%89), uses = [[%93.i0], []];\n",
      "  %94 : Float(100, 32, 27, 27), %95 : Handle = CppOp[ConvForward](%91, %16, %17), uses = [[%96.i0], []];\n",
      "  %96 : Float(100, 32, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%94), uses = [%97.i0, %101.i0];\n",
      "  %98 : Float(100, 128, 27, 27), %99 : Handle = CppOp[ConvForward](%96, %18, %19), uses = [[%100.i0], []];\n",
      "  %100 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%98), uses = [%105.i0];\n",
      "  %102 : Float(100, 128, 27, 27), %103 : Handle = CppOp[ConvForward](%96, %20, %21), uses = [[%104.i0], []];\n",
      "  %104 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%102), uses = [%105.i1];\n",
      "  %105 : Float(100, 256, 27, 27) = cat[dim=1](%100, %104), uses = [%106.i0];\n",
      "  %107 : Float(100, 32, 27, 27), %108 : Handle = CppOp[ConvForward](%105, %22, %23), uses = [[%109.i0], []];\n",
      "  %109 : Float(100, 32, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%107), uses = [%110.i0, %114.i0];\n",
      "  %111 : Float(100, 128, 27, 27), %112 : Handle = CppOp[ConvForward](%109, %24, %25), uses = [[%113.i0], []];\n",
      "  %113 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%111), uses = [%118.i0];\n",
      "  %115 : Float(100, 128, 27, 27), %116 : Handle = CppOp[ConvForward](%109, %26, %27), uses = [[%117.i0], []];\n",
      "  %117 : Float(100, 128, 27, 27) = threshold[threshold={0}, value={0}, inplace=1](%115), uses = [%118.i1];\n",
      "  %118 : Float(100, 256, 27, 27) = cat[dim=1](%113, %117), uses = [%119.i0];\n",
      "  %120 : Float(100, 256, 13, 13), %121 : Long(100, 256, 13, 13) = max_pool2d[kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1], ceil_mode=1](%118), uses = [[%122.i0], []];\n",
      "  %123 : Float(100, 48, 13, 13), %124 : Handle = CppOp[ConvForward](%120, %28, %29), uses = [[%125.i0], []];\n",
      "  %125 : Float(100, 48, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%123), uses = [%126.i0, %130.i0];\n",
      "  %127 : Float(100, 192, 13, 13), %128 : Handle = CppOp[ConvForward](%125, %30, %31), uses = [[%129.i0], []];\n",
      "  %129 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%127), uses = [%134.i0];\n",
      "  %131 : Float(100, 192, 13, 13), %132 : Handle = CppOp[ConvForward](%125, %32, %33), uses = [[%133.i0], []];\n",
      "  %133 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%131), uses = [%134.i1];\n",
      "  %134 : Float(100, 384, 13, 13) = cat[dim=1](%129, %133), uses = [%135.i0];\n",
      "  %136 : Float(100, 48, 13, 13), %137 : Handle = CppOp[ConvForward](%134, %34, %35), uses = [[%138.i0], []];\n",
      "  %138 : Float(100, 48, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%136), uses = [%139.i0, %143.i0];\n",
      "  %140 : Float(100, 192, 13, 13), %141 : Handle = CppOp[ConvForward](%138, %36, %37), uses = [[%142.i0], []];\n",
      "  %142 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%140), uses = [%147.i0];\n",
      "  %144 : Float(100, 192, 13, 13), %145 : Handle = CppOp[ConvForward](%138, %38, %39), uses = [[%146.i0], []];\n",
      "  %146 : Float(100, 192, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%144), uses = [%147.i1];\n",
      "  %147 : Float(100, 384, 13, 13) = cat[dim=1](%142, %146), uses = [%148.i0];\n",
      "  %149 : Float(100, 64, 13, 13), %150 : Handle = CppOp[ConvForward](%147, %40, %41), uses = [[%151.i0], []];\n",
      "  %151 : Float(100, 64, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%149), uses = [%152.i0, %156.i0];\n",
      "  %153 : Float(100, 256, 13, 13), %154 : Handle = CppOp[ConvForward](%151, %42, %43), uses = [[%155.i0], []];\n",
      "  %155 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%153), uses = [%160.i0];\n",
      "  %157 : Float(100, 256, 13, 13), %158 : Handle = CppOp[ConvForward](%151, %44, %45), uses = [[%159.i0], []];\n",
      "  %159 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%157), uses = [%160.i1];\n",
      "  %160 : Float(100, 512, 13, 13) = cat[dim=1](%155, %159), uses = [%161.i0];\n",
      "  %162 : Float(100, 64, 13, 13), %163 : Handle = CppOp[ConvForward](%160, %46, %47), uses = [[%164.i0], []];\n",
      "  %164 : Float(100, 64, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%162), uses = [%165.i0, %169.i0];\n",
      "  %166 : Float(100, 256, 13, 13), %167 : Handle = CppOp[ConvForward](%164, %48, %49), uses = [[%168.i0], []];\n",
      "  %168 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%166), uses = [%173.i0];\n",
      "  %170 : Float(100, 256, 13, 13), %171 : Handle = CppOp[ConvForward](%164, %50, %51), uses = [[%172.i0], []];\n",
      "  %172 : Float(100, 256, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%170), uses = [%173.i1];\n",
      "  %173 : Float(100, 512, 13, 13) = cat[dim=1](%168, %172), uses = [%174.i0];\n",
      "  %175 : Float(100, 512, 13, 13), %176 : Handle = ^Dropout(0.5, False, False)(%173), uses = [[%177.i0], []];\n",
      "  %178 : Float(100, 1000, 13, 13), %179 : Handle = CppOp[ConvForward](%175, %52, %53), uses = [[%180.i0], []];\n",
      "  %180 : Float(100, 1000, 13, 13) = threshold[threshold={0}, value={0}, inplace=1](%178), uses = [%181.i0];\n",
      "  %181 : Float(100, 1000, 1, 1) = avg_pool2d[kernel_size=[13, 13], stride=[13, 13], padding=[0, 0], ceil_mode=0, count_include_pad=1](%180), uses = [%182.i0];\n",
      "  %182 : Float(100, 1000) = view[size=[100, 1000]](%181), uses = [%0.i0];\n",
      "  return (%182);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : 0\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 3, 3, 3])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : 0_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : 1\n",
      "> Not Sequential\n",
      "Looking at : 2\n",
      "> Not Sequential\n",
      "Looking at : 3\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([16, 64, 1, 1])\n",
      "  biases : [o] torch.Size([16])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 16, 1, 1])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 16, 3, 3])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 4\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([16, 128, 1, 1])\n",
      "  biases : [o] torch.Size([16])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 16, 1, 1])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 16, 3, 3])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 5\n",
      "> Not Sequential\n",
      "Looking at : 6\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([32, 128, 1, 1])\n",
      "  biases : [o] torch.Size([32])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([128, 32, 1, 1])\n",
      "  biases : [o] torch.Size([128])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([128, 32, 3, 3])\n",
      "  biases : [o] torch.Size([128])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 7\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([32, 256, 1, 1])\n",
      "  biases : [o] torch.Size([32])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([128, 32, 1, 1])\n",
      "  biases : [o] torch.Size([128])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([128, 32, 3, 3])\n",
      "  biases : [o] torch.Size([128])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 8\n",
      "> Not Sequential\n",
      "Looking at : 9\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([48, 256, 1, 1])\n",
      "  biases : [o] torch.Size([48])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([192, 48, 1, 1])\n",
      "  biases : [o] torch.Size([192])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([192, 48, 3, 3])\n",
      "  biases : [o] torch.Size([192])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 10\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([48, 384, 1, 1])\n",
      "  biases : [o] torch.Size([48])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([192, 48, 1, 1])\n",
      "  biases : [o] torch.Size([192])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([192, 48, 3, 3])\n",
      "  biases : [o] torch.Size([192])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 11\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 384, 1, 1])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([256, 64, 1, 1])\n",
      "  biases : [o] torch.Size([256])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([256, 64, 3, 3])\n",
      "  biases : [o] torch.Size([256])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "Looking at : 12\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : squeeze\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([64, 512, 1, 1])\n",
      "  biases : [o] torch.Size([64])\n",
      "Looking at : squeeze_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : squeeze_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand1x1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([256, 64, 1, 1])\n",
      "  biases : [o] torch.Size([256])\n",
      "Looking at : expand1x1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand1x1_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : expand3x3\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([256, 64, 3, 3])\n",
      "  biases : [o] torch.Size([256])\n",
      "Looking at : expand3x3_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : expand3x3_activation\n",
      "> Not Sequential\n",
      "> Sequential\n",
      "Looking at : 0\n",
      "> Not Sequential\n",
      "Looking at : 1\n",
      "Found Conv2D:\n",
      "  weights: [o,i,k,k] torch.Size([1000, 512, 1, 1])\n",
      "  biases : [o] torch.Size([1000])\n",
      "Looking at : 1_linear_quant\n",
      "> Not Sequential\n",
      "Looking at : 2\n",
      "> Not Sequential\n",
      "Looking at : 3\n",
      "Looking at : 3_linear_quant\n",
      "> Not Sequential\n"
     ]
    }
   ],
   "source": [
    "# We do dumb quantisation; no fine-tuning.\n",
    "\n",
    "weights_bw    = 8\n",
    "biases_bw     = 32\n",
    "activation_bw = 8\n",
    "overflow_rate = 0.0\n",
    "n_sample      = 20\n",
    "quant_method  = \"linear\"\n",
    "    \n",
    "def duplicate_model_with_quant(model, bits, overflow_rate=0.0, counter=10, type='linear'):\n",
    "    \"\"\"assume that original model has at least a nn.Sequential\"\"\"\n",
    "    assert type in ['linear', 'minmax', 'log', 'tanh']\n",
    "    if isinstance(model, nn.Sequential):\n",
    "        print(f'> Sequential')\n",
    "        l = OrderedDict()\n",
    "        for k, v in model._modules.items():\n",
    "            print(f'Looking at : {k}')\n",
    "            if isinstance(v, (nn.Conv2d, nn.Linear, nn.BatchNorm1d, nn.BatchNorm2d, nn.AvgPool2d)):\n",
    "                parameters = list(v.parameters())\n",
    "                if isinstance(v, nn.Conv2d):\n",
    "                    print(f\"Found Conv2D:\")\n",
    "                    print(f\"  weights: [o,i,k,k] {parameters[0].shape}\")\n",
    "                    print(f\"  biases : [o] {parameters[1].shape}\")\n",
    "                l[k] = v\n",
    "                \n",
    "            else:\n",
    "                l[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter, type)\n",
    "        m = nn.Sequential(l)\n",
    "        return m\n",
    "    else:\n",
    "        print(f'> Not Sequential')\n",
    "        for k, v in model._modules.items():\n",
    "            model._modules[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter, type)\n",
    "        return model\n",
    "\n",
    "model_quant = duplicate_model_with_quant(model_raw, bits=activation_bw, overflow_rate=overflow_rate,\n",
    "                                               counter=n_sample, type=quant_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval model\n",
    "val_ds = ds_fetcher(batch_size, data_root=data_root, train=False, input_size=input_size)\n",
    "acc1q, acc5q = misc.eval_model(model_quant, val_ds, ngpu=ngpu, is_imagenet=is_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc1q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-05f918cf8e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc1q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc5q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc1q' is not defined"
     ]
    }
   ],
   "source": [
    "acc1q, acc5q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting model\n",
    "There is the existing ONNX exporter. Either modify that, or manually add functions to each type of Module and call them recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying for quantised training\n",
    "Easiest would be to modify SqN source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "Search GitHub; there seem to be plenty of implementations. E.g. https://github.com/marvis/pytorch-mobilenet\n",
    "There are also implementations for v2.\n",
    "\n",
    "## MobileNet-SSD\n",
    "Try modifying https://github.com/amdegroot/ssd.pytorch:\n",
    "  - Use MobileNet feature extractor\n",
    "  - Use dw convolutions in SSD (SSDLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.group1.squeeze.weight', 'features.3.group1.squeeze.bias', 'features.3.group2.expand1x1.weight', 'features.3.group2.expand1x1.bias', 'features.3.group3.expand3x3.weight', 'features.3.group3.expand3x3.bias', 'features.4.group1.squeeze.weight', 'features.4.group1.squeeze.bias', 'features.4.group2.expand1x1.weight', 'features.4.group2.expand1x1.bias', 'features.4.group3.expand3x3.weight', 'features.4.group3.expand3x3.bias', 'features.6.group1.squeeze.weight', 'features.6.group1.squeeze.bias', 'features.6.group2.expand1x1.weight', 'features.6.group2.expand1x1.bias', 'features.6.group3.expand3x3.weight', 'features.6.group3.expand3x3.bias', 'features.7.group1.squeeze.weight', 'features.7.group1.squeeze.bias', 'features.7.group2.expand1x1.weight', 'features.7.group2.expand1x1.bias', 'features.7.group3.expand3x3.weight', 'features.7.group3.expand3x3.bias', 'features.9.group1.squeeze.weight', 'features.9.group1.squeeze.bias', 'features.9.group2.expand1x1.weight', 'features.9.group2.expand1x1.bias', 'features.9.group3.expand3x3.weight', 'features.9.group3.expand3x3.bias', 'features.10.group1.squeeze.weight', 'features.10.group1.squeeze.bias', 'features.10.group2.expand1x1.weight', 'features.10.group2.expand1x1.bias', 'features.10.group3.expand3x3.weight', 'features.10.group3.expand3x3.bias', 'features.11.group1.squeeze.weight', 'features.11.group1.squeeze.bias', 'features.11.group2.expand1x1.weight', 'features.11.group2.expand1x1.bias', 'features.11.group3.expand3x3.weight', 'features.11.group3.expand3x3.bias', 'features.12.group1.squeeze.weight', 'features.12.group1.squeeze.bias', 'features.12.group2.expand1x1.weight', 'features.12.group2.expand1x1.bias', 'features.12.group3.expand3x3.weight', 'features.12.group3.expand3x3.bias', 'classifier.1.weight', 'classifier.1.bias'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
